"""
Web åº”ç”¨æœåŠ¡

æä¾› FastAPI æœåŠ¡æ¥æ”¯æŒå‰ç«¯ç•Œé¢ä¸ Agent äº¤äº’
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any, TYPE_CHECKING
import os
import json
import re
import hashlib
from pathlib import Path
from langchain_core.messages import HumanMessage

from .agents.simple_agent import SimpleAgent
from .agents.tool_agent import ToolAgent
from .agents.prompt_chaining_agent import (
    PromptChainingAgent,
    DocumentGenerationChain,
    CodeReviewChain,
    ResearchPlanningChain,
    StoryCreationChain,
    ProductAnalysisChain
)
from .agents.routing_agent import (
    RoutingAgent,
    RoutingStrategy,
    SmartAssistantRoutes,
    DeveloperAssistantRoutes
)
from .agents.parallelization_agent import (
    ParallelizationAgent,
    ParallelStrategy,
    AggregationMethod,
    ParallelTask,
    MultiPerspectiveAnalysis,
    ParallelTranslation,
    ParallelContentGeneration,
    ParallelCodeReview,
    ParallelResearch,
    ConsensusGenerator
)
from .tools.basic_tools import get_basic_tools
from .config import settings
from .gitee_ai_client import GiteeAIClient
from .database_helper import DatabaseHelper

# RAG Agent å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…é˜»å¡å¯åŠ¨
# ä½¿ç”¨ TYPE_CHECKING æ¥æ”¯æŒç±»å‹æ³¨è§£è€Œä¸å½±å“è¿è¡Œæ—¶
if TYPE_CHECKING:
    from .rag.rag_agent import RAGAgent

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="ShuYixiao Agent Web Interface",
    description="åŸºäº LangGraph å’Œç äº‘ AI çš„æ™ºèƒ½ Agent Web ç•Œé¢",
    version="0.1.0"
)

# æ·»åŠ  CORS ä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥è®¾ç½®å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# å¯åŠ¨å’Œå…³é—­äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    print("=" * 60)
    print("ğŸš€ ShuYixiao Agent Web åº”ç”¨æ­£åœ¨å¯åŠ¨...")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆä¿®å¤æƒé™ã€æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼‰
    db_initialized = DatabaseHelper.initialize_database(
        db_path=settings.vector_db_path,
        cleanup_temp=True
    )
    
    if not db_initialized:
        print("âš ï¸  è­¦å‘Šï¼šæ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œå¯èƒ½ä¼šé‡åˆ°æƒé™é—®é¢˜")
    
    # æ˜¾ç¤ºæ•°æ®åº“å¥åº·çŠ¶æ€
    health = DatabaseHelper.check_database_health(settings.vector_db_path)
    print(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€: å­˜åœ¨={health['exists']}, å¯è¯»={health['readable']}, å¯å†™={health['writable']}")
    print(f"ğŸ“¦ æ•°æ®åº“å¤§å°: {health['size_mb']} MB, æ–‡ä»¶æ•°: {health['file_count']}")
    
    # ä»æ•°æ®åº“æ¢å¤çŸ¥è¯†åº“åç§°æ˜ å°„å…³ç³»
    print("ğŸ”„ æ­£åœ¨æ¢å¤çŸ¥è¯†åº“åç§°æ˜ å°„å…³ç³»...")
    try:
        import chromadb
        from chromadb.config import Settings as ChromaSettings
        
        client = chromadb.PersistentClient(
            path=settings.vector_db_path,
            settings=ChromaSettings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        collections = client.list_collections()
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½å·²çŸ¥æ˜ å°„ï¼ˆç”¨äºæ—§æ•°æ®ï¼‰
        known_mappings = {}
        mapping_file = Path(__file__).parent.parent.parent / "knowledge_base_mappings.json"
        if mapping_file.exists():
            try:
                import json
                with open(mapping_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    known_mappings = config.get('mappings', {})
                    print(f"  ğŸ“„ å·²åŠ è½½é…ç½®æ–‡ä»¶: {len(known_mappings)} ä¸ªé¢„å®šä¹‰æ˜ å°„")
            except Exception as e:
                print(f"  âš ï¸  åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
        if not known_mappings:
            known_mappings = {
                "kb_dd65ff91_kb": "èˆ’ä¸€ç¬‘ä¸ªäººä¿¡æ¯",  # é»˜è®¤æ˜ å°„
            }
        
        for collection in collections:
            try:
                # ä»collectionçš„metadataä¸­è¯»å–åŸå§‹åç§°
                metadata = collection.metadata or {}
                original_name = metadata.get('original_name')
                
                if original_name and original_name != collection.name:
                    collection_name_mapping[original_name] = collection.name
                    print(f"  âœ“ æ¢å¤æ˜ å°„(ä»metadata): '{original_name}' -> '{collection.name}'")
                elif collection.name in known_mappings:
                    # å¯¹äºæ—§æ•°æ®ï¼Œä½¿ç”¨é¢„å®šä¹‰æ˜ å°„
                    original_name = known_mappings[collection.name]
                    collection_name_mapping[original_name] = collection.name
                    print(f"  âœ“ æ¢å¤æ˜ å°„(å·²çŸ¥æ—§æ•°æ®): '{original_name}' -> '{collection.name}'")
            except Exception as e:
                print(f"  âš ï¸  å¤„ç†collection {collection.name} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… å·²æ¢å¤ {len(collection_name_mapping)} ä¸ªåç§°æ˜ å°„å…³ç³»")
    except Exception as e:
        print(f"âš ï¸  æ¢å¤åç§°æ˜ å°„å¤±è´¥: {e}")
    
    print("=" * 60)
    print("âœ… ShuYixiao Agent Web åº”ç”¨å·²å¯åŠ¨")
    print("=" * 60)
    print(f"API Key å·²é…ç½®: {bool(settings.gitee_ai_api_key)}")
    print(f"ä½¿ç”¨æ¨¡å‹: {settings.gitee_ai_model}")
    print(f"æ•°æ®åº“è·¯å¾„: {settings.vector_db_path}")
    print("=" * 60)


@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    print("ğŸ‘‹ ShuYixiao Agent Web åº”ç”¨å·²å…³é—­")

# Agent å®ä¾‹ç¼“å­˜
agents: Dict[str, Any] = {}

# RAG Agent å®ä¾‹ç¼“å­˜
rag_agents: Dict[str, Any] = {}

# Prompt Chaining Agent å®ä¾‹ç¼“å­˜
prompt_chaining_agent: Optional[PromptChainingAgent] = None

# Routing Agent å®ä¾‹ç¼“å­˜
routing_agents: Dict[str, RoutingAgent] = {}

# Parallelization Agent å®ä¾‹ç¼“å­˜
parallelization_agent: Optional[ParallelizationAgent] = None

# ä¼šè¯æ¶ˆæ¯å†å²ï¼ˆç®€å•å®ç°ï¼Œç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰
session_histories: Dict[str, List[Dict[str, str]]] = {}

# çŸ¥è¯†åº“åç§°æ˜ å°„ï¼ˆåŸå§‹åç§° -> åˆæ³•åç§°ï¼‰
collection_name_mapping: Dict[str, str] = {}


def normalize_collection_name(name: str) -> str:
    """
    å°†ç”¨æˆ·è¾“å…¥çš„åç§°è½¬æ¢ä¸ºç¬¦åˆ ChromaDB è¦æ±‚çš„åˆæ³•åç§°
    
    ChromaDB è¦æ±‚ï¼š
    - 3-512 ä¸ªå­—ç¬¦
    - åªåŒ…å« [a-zA-Z0-9._-]
    - å¿…é¡»ä»¥ [a-zA-Z0-9] å¼€å¤´å’Œç»“å°¾
    
    Args:
        name: ç”¨æˆ·è¾“å…¥çš„åç§°
        
    Returns:
        åˆæ³•çš„é›†åˆåç§°
    """
    # å¦‚æœå·²ç»æ˜¯åˆæ³•åç§°ï¼Œç›´æ¥è¿”å›
    if re.match(r'^[a-zA-Z0-9][a-zA-Z0-9._-]{1,510}[a-zA-Z0-9]$', name):
        return name
    
    # å¦‚æœåç§°å·²ç»è¢«æ˜ å°„è¿‡ï¼Œè¿”å›ä¹‹å‰çš„æ˜ å°„
    if name in collection_name_mapping:
        return collection_name_mapping[name]
    
    # ç”Ÿæˆä¸€ä¸ªåŸºäºåŸå§‹åç§°çš„å“ˆå¸Œå€¼ï¼ˆä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼‰
    name_hash = hashlib.md5(name.encode('utf-8')).hexdigest()[:8]
    
    # å°è¯•ä»åç§°ä¸­æå–åˆæ³•å­—ç¬¦ä½œä¸ºå‰ç¼€ï¼ˆæé«˜å¯è¯»æ€§ï¼‰
    safe_prefix = re.sub(r'[^a-zA-Z0-9._-]', '', name)
    
    # ç§»é™¤å‰åçš„éæ³•å­—ç¬¦
    safe_prefix = safe_prefix.strip('._-')
    
    # å¦‚æœæ²¡æœ‰åˆæ³•å­—ç¬¦æˆ–å¤ªçŸ­ï¼Œä½¿ç”¨æœ‰æ„ä¹‰çš„é»˜è®¤å‰ç¼€
    if not safe_prefix or len(safe_prefix) < 2:
        safe_prefix = "kb"  # knowledge base
    else:
        # é™åˆ¶å‰ç¼€é•¿åº¦ï¼Œä¸ºå“ˆå¸Œå€¼ç•™å‡ºç©ºé—´
        safe_prefix = safe_prefix[:20]
    
    # ç»„åˆå‰ç¼€å’Œå“ˆå¸Œå€¼ï¼ˆå“ˆå¸Œå€¼ç¡®ä¿å”¯ä¸€æ€§ï¼Œå‰ç¼€æé«˜å¯è¯»æ€§ï¼‰
    normalized_name = f"{safe_prefix}_{name_hash}"
    
    # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ä»¥å­—æ¯æˆ–æ•°å­—å¼€å¤´å’Œç»“å°¾
    if not re.match(r'^[a-zA-Z0-9]', normalized_name):
        normalized_name = "kb_" + normalized_name
    if not re.match(r'[a-zA-Z0-9]$', normalized_name):
        normalized_name = normalized_name + "_kb"
    
    # ç¡®ä¿é•¿åº¦åœ¨èŒƒå›´å†…
    if len(normalized_name) < 3:
        normalized_name = "kb_" + name_hash + "_default"
    elif len(normalized_name) > 512:
        normalized_name = normalized_name[:512]
        # ç¡®ä¿æˆªæ–­åä»ä»¥å­—æ¯æˆ–æ•°å­—ç»“å°¾
        if not re.match(r'[a-zA-Z0-9]$', normalized_name):
            normalized_name = normalized_name.rstrip('._-')
    
    # ä¿å­˜æ˜ å°„å…³ç³»
    collection_name_mapping[name] = normalized_name
    
    print(f"[çŸ¥è¯†åº“åç§°] '{name}' -> '{normalized_name}'")
    
    return normalized_name


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str
    agent_type: str = "simple"  # simple, tool, rag, æˆ– prompt_chaining
    session_id: Optional[str] = "default"
    system_message: Optional[str] = None
    collection_name: Optional[str] = "default"  # RAG ä¸“ç”¨ï¼šçŸ¥è¯†åº“é›†åˆå


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    response: str
    agent_type: str
    session_id: str


class SessionHistoryResponse(BaseModel):
    """ä¼šè¯å†å²å“åº”æ¨¡å‹"""
    session_id: str
    messages: List[Dict[str, str]]


class DocumentUploadRequest(BaseModel):
    """æ–‡æ¡£ä¸Šä¼ è¯·æ±‚æ¨¡å‹"""
    file_path: str
    collection_name: Optional[str] = "default"


class DirectoryUploadRequest(BaseModel):
    """ç›®å½•ä¸Šä¼ è¯·æ±‚æ¨¡å‹"""
    directory_path: str
    glob_pattern: Optional[str] = "**/*.*"
    collection_name: Optional[str] = "default"


class TextUploadRequest(BaseModel):
    """æ–‡æœ¬ä¸Šä¼ è¯·æ±‚æ¨¡å‹"""
    texts: List[str]
    metadatas: Optional[List[Dict[str, Any]]] = None
    collection_name: Optional[str] = "default"


class RAGQueryRequest(BaseModel):
    """RAG æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    question: str
    collection_name: Optional[str] = "default"
    session_id: Optional[str] = "default"
    top_k: Optional[int] = None
    use_history: bool = True
    optimize_query: bool = True


class PromptChainingRequest(BaseModel):
    """Prompt Chaining è¯·æ±‚æ¨¡å‹"""
    input_text: str
    chain_type: str  # document_gen, code_review, research, story, product
    save_result: bool = True


class RoutingRequest(BaseModel):
    """Routing è¯·æ±‚æ¨¡å‹"""
    input_text: str
    scenario: str = "smart_assistant"  # smart_assistant, developer_assistant, custom
    strategy: str = "hybrid"  # rule_based, keyword, llm_based, hybrid
    verbose: bool = False


class ParallelizationRequest(BaseModel):
    """Parallelization è¯·æ±‚æ¨¡å‹"""
    scenario: str  # multi_perspective, translation, content_gen, code_review, research, consensus, custom
    input_text: str
    strategy: str = "full_parallel"  # full_parallel, batch_parallel, pipeline, vote, ensemble
    aggregation: str = "summarize"  # merge, concat, first, best, summarize, vote, consensus
    perspectives: Optional[List[str]] = None  # ç”¨äº multi_perspective
    languages: Optional[List[str]] = None  # ç”¨äº translation
    sections: Optional[List[str]] = None  # ç”¨äº content_gen
    aspects: Optional[List[str]] = None  # ç”¨äº research
    num_generations: Optional[int] = 5  # ç”¨äº consensus
    batch_size: int = 3
    max_workers: int = 5


def get_agent(agent_type: str, system_message: Optional[str] = None):
    """è·å–æˆ–åˆ›å»º Agent å®ä¾‹"""
    cache_key = f"{agent_type}_{system_message or 'default'}"
    
    if cache_key not in agents:
        if agent_type == "simple":
            agents[cache_key] = SimpleAgent(
                system_message=system_message or "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œè¯·å‹å¥½ã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
            )
        elif agent_type == "tool":
            agent = ToolAgent(
                system_message=system_message or "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚ä½ å¯ä»¥ä½¿ç”¨æä¾›çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚"
            )
            # æ³¨å†ŒåŸºç¡€å·¥å…·
            for tool_info in get_basic_tools():
                agent.register_tool(
                    name=tool_info["name"],
                    func=tool_info["func"],
                    description=tool_info["description"],
                    parameters=tool_info["parameters"]
                )
            agents[cache_key] = agent
        else:
            raise ValueError(f"æœªçŸ¥çš„ agent ç±»å‹: {agent_type}")
    
    return agents[cache_key]


def get_rag_agent(collection_name: str = "default"):
    """è·å–æˆ–åˆ›å»º RAG Agent å®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
    # è½¬æ¢ä¸ºåˆæ³•çš„é›†åˆåç§°
    normalized_name = normalize_collection_name(collection_name)
    
    # ä½¿ç”¨è½¬æ¢åçš„åç§°ä½œä¸ºç¼“å­˜é”®
    if normalized_name not in rag_agents:
        # å»¶è¿Ÿå¯¼å…¥ RAG Agent
        from .rag.rag_agent import RAGAgent
        
        print(f"[ä¿¡æ¯] é¦–æ¬¡åˆ›å»º RAG Agent: {collection_name} (å®é™…é›†åˆ: {normalized_name})")
        rag_agents[normalized_name] = RAGAgent(
            collection_name=normalized_name,
            system_message="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚",
            use_reranker=True,
            retrieval_mode="hybrid",
            enable_query_optimization=True,
            enable_context_expansion=True,
            original_name=collection_name  # ä¼ é€’åŸå§‹åç§°ç”¨äºæŒä¹…åŒ–
        )
        print(f"[æˆåŠŸ] RAG Agent åˆ›å»ºå®Œæˆ: {normalized_name}")
    
    return rag_agents[normalized_name]


def get_prompt_chaining_agent():
    """è·å–æˆ–åˆ›å»º Prompt Chaining Agent å®ä¾‹"""
    global prompt_chaining_agent
    
    if prompt_chaining_agent is None:
        llm_client = GiteeAIClient()
        prompt_chaining_agent = PromptChainingAgent(llm_client, verbose=False)
        print("[ä¿¡æ¯] Prompt Chaining Agent å·²åˆ›å»º")
    
    return prompt_chaining_agent


def get_routing_agent(scenario: str = "smart_assistant", strategy: str = "hybrid"):
    """è·å–æˆ–åˆ›å»º Routing Agent å®ä¾‹"""
    cache_key = f"{scenario}_{strategy}"
    
    if cache_key not in routing_agents:
        llm_client = GiteeAIClient()
        agent = RoutingAgent(
            llm_client=llm_client,
            strategy=RoutingStrategy(strategy),
            verbose=False
        )
        
        # æ ¹æ®åœºæ™¯æ³¨å†Œè·¯ç”±
        if scenario == "smart_assistant":
            routes = SmartAssistantRoutes.get_routes(llm_client)
            agent.register_routes(routes)
        elif scenario == "developer_assistant":
            routes = DeveloperAssistantRoutes.get_routes(llm_client)
            agent.register_routes(routes)
        
        routing_agents[cache_key] = agent
        print(f"[ä¿¡æ¯] Routing Agent å·²åˆ›å»º: {scenario} ({strategy})")
    
    return routing_agents[cache_key]


def get_parallelization_agent(max_workers: int = 5):
    """è·å–æˆ–åˆ›å»º Parallelization Agent å®ä¾‹"""
    global parallelization_agent
    
    if parallelization_agent is None or parallelization_agent.max_workers != max_workers:
        llm_client = GiteeAIClient()
        parallelization_agent = ParallelizationAgent(
            llm_client=llm_client,
            max_workers=max_workers,
            verbose=False
        )
        print(f"[ä¿¡æ¯] Parallelization Agent å·²åˆ›å»º (max_workers={max_workers})")
    
    return parallelization_agent


@app.get("/", response_class=HTMLResponse)
async def read_root():
    """è¿”å›å‰ç«¯ HTML é¡µé¢"""
    print(f"[è¯·æ±‚] GET / - è¿”å›ä¸»é¡µ")
    
    static_dir = Path(__file__).parent / "static"
    html_file = static_dir / "index.html"
    
    print(f"[ä¿¡æ¯] é™æ€æ–‡ä»¶ç›®å½•: {static_dir}")
    print(f"[ä¿¡æ¯] HTML æ–‡ä»¶è·¯å¾„: {html_file}")
    print(f"[ä¿¡æ¯] æ–‡ä»¶å­˜åœ¨: {html_file.exists()}")
    
    if html_file.exists():
        content = html_file.read_text(encoding="utf-8")
        print(f"[æˆåŠŸ] è¿”å› HTML æ–‡ä»¶, å¤§å°: {len(content)} å­—ç¬¦")
        return HTMLResponse(content=content)
    else:
        print(f"[è­¦å‘Š] HTML æ–‡ä»¶ä¸å­˜åœ¨: {html_file}")
        return HTMLResponse(content="""
        <html>
            <body>
                <h1>å‰ç«¯é¡µé¢æœªæ‰¾åˆ°</h1>
                <p>è¯·ç¡®ä¿ static/index.html æ–‡ä»¶å­˜åœ¨</p>
            </body>
        </html>
        """)


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """å¤„ç†èŠå¤©è¯·æ±‚ï¼ˆéæµå¼ï¼‰"""
    try:
        # è·å– Agent
        agent = get_agent(request.agent_type, request.system_message)
        
        # åˆå§‹åŒ–ä¼šè¯å†å²
        if request.session_id not in session_histories:
            session_histories[request.session_id] = []
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        session_histories[request.session_id].append({
            "role": "user",
            "content": request.message
        })
        
        # è°ƒç”¨ Agent
        if request.agent_type == "simple":
            response = agent.chat(request.message)
        else:  # tool agent
            response = agent.run(request.message)
        
        # æ·»åŠ  AI å›å¤åˆ°å†å²
        session_histories[request.session_id].append({
            "role": "assistant",
            "content": response
        })
        
        return ChatResponse(
            response=response,
            agent_type=request.agent_type,
            session_id=request.session_id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    """å¤„ç†èŠå¤©è¯·æ±‚ï¼ˆæµå¼ï¼‰"""
    
    async def generate():
        try:
            # åˆå§‹åŒ–ä¼šè¯å†å²
            if request.session_id not in session_histories:
                session_histories[request.session_id] = []
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            session_histories[request.session_id].append({
                "role": "user",
                "content": request.message
            })
            
            # æ„å»ºæ¶ˆæ¯å†å²
            messages = []
            
            # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
            system_message = request.system_message or "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ï¼Œè¯·å‹å¥½ã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
            messages.append({
                "role": "system",
                "content": system_message
            })
            
            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆæœ€è¿‘10æ¡ï¼‰
            recent_history = session_histories[request.session_id][-10:]
            messages.extend(recent_history)
            
            # åˆ›å»ºå®¢æˆ·ç«¯å¹¶è°ƒç”¨æµå¼API
            client = GiteeAIClient()
            full_response = ""
            
            # å¯¹äºå·¥å…·è°ƒç”¨æ¨¡å¼ï¼Œæš‚æ—¶ä½¿ç”¨éæµå¼ï¼ˆå› ä¸ºéœ€è¦å¤„ç†å·¥å…·è°ƒç”¨ï¼‰
            if request.agent_type == "tool":
                agent = get_agent(request.agent_type, request.system_message)
                response = agent.run(request.message)
                full_response = response
                
                # ä¸€æ¬¡æ€§å‘é€
                yield f"data: {json.dumps({'content': response, 'done': True}, ensure_ascii=False)}\n\n"
            else:
                # ç®€å•å¯¹è¯æ¨¡å¼ä½¿ç”¨æµå¼
                stream = client.chat_completion(messages=messages, stream=True)
                
                for chunk in stream:
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        delta = chunk["choices"][0].get("delta", {})
                        content = delta.get("content", "")
                        
                        if content:
                            full_response += content
                            # å‘é€æ•°æ®å—
                            yield f"data: {json.dumps({'content': content, 'done': False}, ensure_ascii=False)}\n\n"
                
                # å‘é€å®Œæˆä¿¡å·
                yield f"data: {json.dumps({'content': '', 'done': True}, ensure_ascii=False)}\n\n"
            
            # æ·»åŠ å®Œæ•´å›å¤åˆ°å†å²
            session_histories[request.session_id].append({
                "role": "assistant",
                "content": full_response
            })
            
        except Exception as e:
            error_msg = f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            yield f"data: {json.dumps({'error': error_msg, 'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/api/history/{session_id}", response_model=SessionHistoryResponse)
async def get_history(session_id: str):
    """è·å–ä¼šè¯å†å²"""
    if session_id not in session_histories:
        session_histories[session_id] = []
    
    return SessionHistoryResponse(
        session_id=session_id,
        messages=session_histories[session_id]
    )


@app.delete("/api/history/{session_id}")
async def clear_history(session_id: str):
    """æ¸…é™¤ä¼šè¯å†å²"""
    if session_id in session_histories:
        session_histories[session_id] = []
    return {"message": "å†å²å·²æ¸…é™¤", "session_id": session_id}


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    print(f"[è¯·æ±‚] GET /api/health - å¥åº·æ£€æŸ¥")
    result = {
        "status": "healthy",
        "api_key_configured": bool(settings.gitee_ai_api_key),
        "model": settings.gitee_ai_model
    }
    print(f"[å“åº”] å¥åº·æ£€æŸ¥: {result}")
    return result


# ========== RAG ç›¸å…³æ¥å£ ==========

@app.post("/api/rag/upload/file")
async def upload_file(request: DocumentUploadRequest):
    """ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°çŸ¥è¯†åº“"""
    try:
        # è·å–è§„èŒƒåŒ–åçš„é›†åˆåç§°
        normalized_name = normalize_collection_name(request.collection_name)
        agent = get_rag_agent(request.collection_name)
        count = agent.add_documents_from_file(
            request.file_path,
            show_progress=True
        )
        
        return {
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
            "collection_name": normalized_name,  # è¿”å›è§„èŒƒåŒ–åçš„åç§°
            "original_name": request.collection_name,  # ä¿ç•™åŸå§‹åç§°
            "chunks_added": count,
            "total_documents": agent.get_document_count()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")


@app.post("/api/rag/upload/directory")
async def upload_directory(request: DirectoryUploadRequest):
    """ä¸Šä¼ æ•´ä¸ªç›®å½•åˆ°çŸ¥è¯†åº“"""
    try:
        # è·å–è§„èŒƒåŒ–åçš„é›†åˆåç§°
        normalized_name = normalize_collection_name(request.collection_name)
        agent = get_rag_agent(request.collection_name)
        count = agent.add_documents_from_directory(
            request.directory_path,
            request.glob_pattern,
            show_progress=True
        )
        
        return {
            "message": "ç›®å½•ä¸Šä¼ æˆåŠŸ",
            "collection_name": normalized_name,  # è¿”å›è§„èŒƒåŒ–åçš„åç§°
            "original_name": request.collection_name,  # ä¿ç•™åŸå§‹åç§°
            "chunks_added": count,
            "total_documents": agent.get_document_count()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ ç›®å½•å¤±è´¥: {str(e)}")


@app.post("/api/rag/upload/texts")
async def upload_texts(request: TextUploadRequest):
    """ä¸Šä¼ æ–‡æœ¬åˆ—è¡¨åˆ°çŸ¥è¯†åº“"""
    try:
        # è·å–è§„èŒƒåŒ–åçš„é›†åˆåç§°
        normalized_name = normalize_collection_name(request.collection_name)
        agent = get_rag_agent(request.collection_name)
        count = agent.add_texts(
            request.texts,
            request.metadatas
        )
        
        return {
            "message": "æ–‡æœ¬ä¸Šä¼ æˆåŠŸ",
            "collection_name": normalized_name,  # è¿”å›è§„èŒƒåŒ–åçš„åç§°
            "original_name": request.collection_name,  # ä¿ç•™åŸå§‹åç§°
            "chunks_added": count,
            "total_documents": agent.get_document_count()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ æ–‡æœ¬å¤±è´¥: {str(e)}")


@app.post("/api/rag/query")
async def rag_query(request: RAGQueryRequest):
    """RAG æŸ¥è¯¢ï¼ˆéæµå¼ï¼‰"""
    try:
        agent = get_rag_agent(request.collection_name)
        
        answer = agent.query(
            question=request.question,
            top_k=request.top_k,
            use_history=request.use_history,
            optimize_query=request.optimize_query,
            stream=False
        )
        
        return {
            "answer": answer,
            "collection_name": request.collection_name,
            "session_id": request.session_id
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@app.post("/api/rag/query/stream")
async def rag_query_stream(request: RAGQueryRequest):
    """RAG æŸ¥è¯¢ï¼ˆæµå¼ï¼‰"""
    
    async def generate():
        try:
            agent = get_rag_agent(request.collection_name)
            
            # è·å–æµå¼å“åº”
            stream = agent.query(
                question=request.question,
                top_k=request.top_k,
                use_history=request.use_history,
                optimize_query=request.optimize_query,
                stream=True
            )
            
            # å‘é€æµå¼æ•°æ®
            for chunk in stream:
                yield f"data: {json.dumps({'content': chunk, 'done': False}, ensure_ascii=False)}\n\n"
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'content': '', 'done': True}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            error_msg = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
            yield f"data: {json.dumps({'error': error_msg, 'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/api/rag/info/{collection_name}")
async def get_rag_info(collection_name: str):
    """è·å– RAG çŸ¥è¯†åº“ä¿¡æ¯"""
    try:
        # è·å–è§„èŒƒåŒ–åçš„åç§°
        normalized_name = normalize_collection_name(collection_name)
        agent = get_rag_agent(collection_name)
        
        # æŸ¥æ‰¾åŸå§‹åç§°ï¼ˆåå‘æ˜ å°„ï¼‰
        original_name = collection_name
        for orig, norm in collection_name_mapping.items():
            if norm == normalized_name:
                original_name = orig
                break
        
        return {
            "collection_name": normalized_name,
            "original_name": original_name if original_name != normalized_name else None,
            "is_normalized": original_name != normalized_name,
            "document_count": agent.get_document_count(),
            "retrieval_mode": agent.retrieval_mode
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.get("/api/rag/mappings")
async def get_collection_mappings():
    """è·å–æ‰€æœ‰çŸ¥è¯†åº“åç§°æ˜ å°„å…³ç³»"""
    try:
        mappings = []
        for original_name, normalized_name in collection_name_mapping.items():
            # å°è¯•è·å–æ–‡æ¡£æ•°é‡
            try:
                if normalized_name in rag_agents:
                    agent = rag_agents[normalized_name]
                    doc_count = agent.get_document_count()
                else:
                    doc_count = None
            except:
                doc_count = None
            
            mappings.append({
                "original_name": original_name,
                "normalized_name": normalized_name,
                "document_count": doc_count
            })
        
        return {
            "mappings": mappings,
            "total_count": len(mappings)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ˜ å°„å¤±è´¥: {str(e)}")


@app.delete("/api/rag/clear/{collection_name}")
async def clear_rag_knowledge_base(collection_name: str):
    """æ¸…ç©º RAG çŸ¥è¯†åº“"""
    try:
        agent = get_rag_agent(collection_name)
        agent.clear_knowledge_base()
        
        return {
            "message": "çŸ¥è¯†åº“å·²æ¸…ç©º",
            "collection_name": collection_name
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºçŸ¥è¯†åº“å¤±è´¥: {str(e)}")


@app.delete("/api/rag/history/{collection_name}/{session_id}")
async def clear_rag_history(collection_name: str, session_id: str):
    """æ¸…ç©º RAG å¯¹è¯å†å²"""
    try:
        agent = get_rag_agent(collection_name)
        agent.clear_history()
        
        return {
            "message": "å¯¹è¯å†å²å·²æ¸…ç©º",
            "collection_name": collection_name,
            "session_id": session_id
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºå†å²å¤±è´¥: {str(e)}")


@app.get("/api/rag/documents/{collection_name}")
async def list_documents(
    collection_name: str,
    limit: Optional[int] = None,
    offset: Optional[int] = None
):
    """åˆ—å‡ºçŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£"""
    try:
        agent = get_rag_agent(collection_name)
        documents = agent.list_documents(limit=limit, offset=offset)
        
        return {
            "collection_name": collection_name,
            "total_count": agent.get_document_count(),
            "documents": documents,
            "count": len(documents)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.get("/api/rag/document/{collection_name}/{doc_id}")
async def get_document(collection_name: str, doc_id: str):
    """è·å–å•ä¸ªæ–‡æ¡£å†…å®¹"""
    try:
        agent = get_rag_agent(collection_name)
        document = agent.get_document_by_id(doc_id)
        
        if document is None:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
        
        return {
            "collection_name": collection_name,
            "document": document
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£å¤±è´¥: {str(e)}")


@app.delete("/api/rag/document/{collection_name}/{doc_id}")
async def delete_document(collection_name: str, doc_id: str):
    """åˆ é™¤æŒ‡å®šæ–‡æ¡£"""
    try:
        agent = get_rag_agent(collection_name)
        success = agent.delete_document(doc_id)
        
        if not success:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨æˆ–åˆ é™¤å¤±è´¥")
        
        return {
            "message": "æ–‡æ¡£å·²åˆ é™¤",
            "collection_name": collection_name,
            "document_id": doc_id,
            "remaining_count": agent.get_document_count()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")


@app.get("/api/rag/collections")
async def list_collections():
    """åˆ—å‡ºæ‰€æœ‰å·²å­˜åœ¨çš„çŸ¥è¯†åº“é›†åˆ"""
    try:
        import chromadb
        from chromadb.config import Settings as ChromaSettings
        
        print(f"[åˆ—å‡ºCollections] å¼€å§‹æ‰«ææ•°æ®åº“è·¯å¾„: {settings.vector_db_path}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯è¿æ¥åˆ°æŒä¹…åŒ–ç›®å½•
        client = chromadb.PersistentClient(
            path=settings.vector_db_path,
            settings=ChromaSettings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # è·å–æ‰€æœ‰é›†åˆ
        collections = client.list_collections()
        print(f"[åˆ—å‡ºCollections] æ‰¾åˆ° {len(collections)} ä¸ªé›†åˆ")
        
        result = []
        for collection in collections:
            try:
                collection_name = collection.name
                doc_count = collection.count()
                
                print(f"[åˆ—å‡ºCollections] å¤„ç†é›†åˆ: {collection_name}, æ–‡æ¡£æ•°: {doc_count}")
                
                # ä¼˜å…ˆä»collection metadataä¸­è¯»å–åŸå§‹åç§°
                metadata = collection.metadata or {}
                original_name = metadata.get('original_name')
                
                # å¦‚æœmetadataä¸­æ²¡æœ‰ï¼Œå°è¯•ä»å†…å­˜æ˜ å°„è¡¨ä¸­æŸ¥æ‰¾ï¼ˆåŒ…æ‹¬é¢„å®šä¹‰çš„æ—§æ•°æ®æ˜ å°„ï¼‰
                if not original_name:
                    for orig, norm in collection_name_mapping.items():
                        if norm == collection_name:
                            original_name = orig
                            break
                
                # å¦‚æœè¿˜æ˜¯æ²¡æœ‰åŸå§‹åç§°ï¼Œè¯´æ˜è¯¥collectionåç§°æœ¬èº«å°±æ˜¯åˆæ³•çš„
                if not original_name:
                    original_name = collection_name
                
                is_normalized = original_name != collection_name
                
                print(f"[åˆ—å‡ºCollections] é›†åˆ: {collection_name}, åŸå§‹åç§°: {original_name}, æ˜¯å¦è½¬æ¢: {is_normalized}")
                
                result.append({
                    "collection_name": collection_name,
                    "original_name": original_name if is_normalized else None,
                    "document_count": doc_count,
                    "is_normalized": is_normalized
                })
            except Exception as coll_error:
                print(f"[åˆ—å‡ºCollections] å¤„ç†é›†åˆ {collection.name} æ—¶å‡ºé”™: {coll_error}")
                # ç»§ç»­å¤„ç†å…¶ä»–é›†åˆ
                continue
        
        print(f"[åˆ—å‡ºCollections] æˆåŠŸè¿”å› {len(result)} ä¸ªé›†åˆä¿¡æ¯")
        return {
            "collections": result,
            "total_count": len(result)
        }
    except Exception as e:
        import traceback
        error_detail = f"è·å–é›†åˆåˆ—è¡¨å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(f"[åˆ—å‡ºCollections] é”™è¯¯: {error_detail}")
        raise HTTPException(status_code=500, detail=f"è·å–é›†åˆåˆ—è¡¨å¤±è´¥: {str(e)}")


class BatchDeleteRequest(BaseModel):
    """æ‰¹é‡åˆ é™¤è¯·æ±‚æ¨¡å‹"""
    doc_ids: List[str]
    collection_name: str


@app.delete("/api/rag/documents/batch")
async def batch_delete_documents(request: BatchDeleteRequest):
    """æ‰¹é‡åˆ é™¤æ–‡æ¡£ï¼ˆç‰©ç†åˆ é™¤ï¼‰"""
    try:
        agent = get_rag_agent(request.collection_name)
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡åˆ é™¤æ–¹æ³•
        success_count, failed_ids = agent.batch_delete_documents(request.doc_ids)
        
        return {
            "message": f"æ‰¹é‡åˆ é™¤å®Œæˆï¼ˆå·²ç‰©ç†åˆ é™¤ï¼‰",
            "collection_name": request.collection_name,
            "success_count": success_count,
            "failed_count": len(failed_ids),
            "failed_ids": failed_ids,
            "remaining_count": agent.get_document_count()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ é™¤å¤±è´¥: {str(e)}")


# ========== Prompt Chaining ç›¸å…³æ¥å£ ==========

@app.post("/api/prompt-chaining/run")
async def run_prompt_chain(request: PromptChainingRequest):
    """è¿è¡Œæç¤ºé“¾ï¼ˆéæµå¼ï¼‰"""
    try:
        agent = get_prompt_chaining_agent()
        
        # æ ¹æ®ç±»å‹é€‰æ‹©å¯¹åº”çš„é“¾
        chain_types = {
            "document_gen": ("æ–‡æ¡£ç”Ÿæˆ", DocumentGenerationChain.get_steps()),
            "code_review": ("ä»£ç å®¡æŸ¥", CodeReviewChain.get_steps()),
            "research": ("ç ”ç©¶è§„åˆ’", ResearchPlanningChain.get_steps()),
            "story": ("æ•…äº‹åˆ›ä½œ", StoryCreationChain.get_steps()),
            "product": ("äº§å“åˆ†æ", ProductAnalysisChain.get_steps())
        }
        
        if request.chain_type not in chain_types:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„é“¾ç±»å‹: {request.chain_type}"
            )
        
        chain_name, steps = chain_types[request.chain_type]
        
        # åˆ›å»ºå¹¶è¿è¡Œé“¾
        agent.create_chain(request.chain_type, steps)
        result = agent.run_chain(request.chain_type, request.input_text)
        
        if not result.success:
            raise HTTPException(
                status_code=500,
                detail=f"é“¾æ‰§è¡Œå¤±è´¥: {result.error_message}"
            )
        
        # å¯é€‰ï¼šä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = None
        if request.save_result:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"prompt_chain_{request.chain_type}_{timestamp}.md"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"# {chain_name}ç»“æœ\n\n")
                f.write(f"**è¾“å…¥:** {request.input_text}\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("---\n\n")
                f.write(result.final_output)
        
        return {
            "success": True,
            "chain_type": request.chain_type,
            "chain_name": chain_name,
            "final_output": result.final_output,
            "total_steps": result.total_steps,
            "execution_time": result.execution_time,
            "output_file": output_file,
            "intermediate_results": [
                {
                    "step": r["step"],
                    "name": r["name"],
                    "output": r["output"]
                }
                for r in result.intermediate_results
            ]
        }
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œæç¤ºé“¾å¤±è´¥: {str(e)}")


@app.post("/api/prompt-chaining/run/stream")
async def run_prompt_chain_stream(request: PromptChainingRequest):
    """è¿è¡Œæç¤ºé“¾ï¼ˆæµå¼ï¼Œé€æ­¥è¿”å›ç»“æœï¼‰"""
    
    async def generate():
        try:
            agent = get_prompt_chaining_agent()
            
            # æ ¹æ®ç±»å‹é€‰æ‹©å¯¹åº”çš„é“¾
            chain_types = {
                "document_gen": ("æ–‡æ¡£ç”Ÿæˆ", DocumentGenerationChain.get_steps()),
                "code_review": ("ä»£ç å®¡æŸ¥", CodeReviewChain.get_steps()),
                "research": ("ç ”ç©¶è§„åˆ’", ResearchPlanningChain.get_steps()),
                "story": ("æ•…äº‹åˆ›ä½œ", StoryCreationChain.get_steps()),
                "product": ("äº§å“åˆ†æ", ProductAnalysisChain.get_steps())
            }
            
            if request.chain_type not in chain_types:
                yield f"data: {json.dumps({'error': f'ä¸æ”¯æŒçš„é“¾ç±»å‹: {request.chain_type}', 'done': True}, ensure_ascii=False)}\n\n"
                return
            
            chain_name, steps = chain_types[request.chain_type]
            
            # å‘é€é“¾ä¿¡æ¯
            yield f"data: {json.dumps({'type': 'info', 'chain_name': chain_name, 'total_steps': len(steps)}, ensure_ascii=False)}\n\n"
            
            # é€æ­¥æ‰§è¡Œé“¾
            current_input = request.input_text
            llm_client = GiteeAIClient()
            
            for i, step in enumerate(steps, 1):
                # å‘é€æ­¥éª¤å¼€å§‹ä¿¡å·
                yield f"data: {json.dumps({'type': 'step_start', 'step': i, 'name': step.name, 'description': step.description}, ensure_ascii=False)}\n\n"
                
                # æ ¼å¼åŒ–æç¤ºè¯
                prompt = step.prompt_template.format(input=current_input)
                
                # è°ƒç”¨ LLMï¼ˆæµå¼ï¼‰
                full_output = ""
                stream = llm_client.chat_completion(
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                
                for chunk in stream:
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        delta = chunk["choices"][0].get("delta", {})
                        content = delta.get("content", "")
                        
                        if content:
                            full_output += content
                            # å‘é€å†…å®¹å—
                            yield f"data: {json.dumps({'type': 'content', 'step': i, 'content': content}, ensure_ascii=False)}\n\n"
                
                # åº”ç”¨è½¬æ¢å‡½æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
                if step.transform_fn:
                    full_output = step.transform_fn(full_output)
                
                # å‘é€æ­¥éª¤å®Œæˆä¿¡å·
                yield f"data: {json.dumps({'type': 'step_complete', 'step': i, 'output': full_output}, ensure_ascii=False)}\n\n"
                
                # ä¸‹ä¸€æ­¥çš„è¾“å…¥æ˜¯å½“å‰æ­¥çš„è¾“å‡º
                current_input = full_output
            
            # å¯é€‰ï¼šä¿å­˜ç»“æœ
            output_file = None
            if request.save_result:
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"prompt_chain_{request.chain_type}_{timestamp}.md"
                
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(f"# {chain_name}ç»“æœ\n\n")
                    f.write(f"**è¾“å…¥:** {request.input_text}\n\n")
                    f.write(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    f.write("---\n\n")
                    f.write(current_input)
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'done', 'final_output': current_input, 'output_file': output_file}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            error_msg = f"æ‰§è¡Œæç¤ºé“¾å¤±è´¥: {str(e)}"
            yield f"data: {json.dumps({'error': error_msg, 'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/api/prompt-chaining/types")
async def get_chain_types():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æç¤ºé“¾ç±»å‹"""
    return {
        "chain_types": [
            {
                "id": "document_gen",
                "name": "æ–‡æ¡£ç”Ÿæˆ",
                "description": "æ ¹æ®ä¸»é¢˜è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æŠ€æœ¯æ–‡æ¡£",
                "steps": ["ç”Ÿæˆå¤§çº²", "æ’°å†™å†…å®¹", "æ·»åŠ ç¤ºä¾‹", "ä¼˜åŒ–æ¶¦è‰²"],
                "input_hint": "è¯·è¾“å…¥æ–‡æ¡£ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šPython å¼‚æ­¥ç¼–ç¨‹å…¥é—¨"
            },
            {
                "id": "code_review",
                "name": "ä»£ç å®¡æŸ¥",
                "description": "ç³»ç»ŸåŒ–çš„ä»£ç å®¡æŸ¥å’Œæ”¹è¿›å»ºè®®",
                "steps": ["ç†è§£ä»£ç ", "æ£€æŸ¥é—®é¢˜", "æå‡ºå»ºè®®", "ç”ŸæˆæŠ¥å‘Š"],
                "input_hint": "è¯·ç²˜è´´è¦å®¡æŸ¥çš„ä»£ç "
            },
            {
                "id": "research",
                "name": "ç ”ç©¶è§„åˆ’",
                "description": "å°†ç ”ç©¶é—®é¢˜è½¬åŒ–ä¸ºç³»ç»ŸåŒ–çš„ç ”ç©¶è®¡åˆ’",
                "steps": ["é—®é¢˜åˆ†æ", "æ–‡çŒ®ç»¼è¿°", "ç ”ç©¶æ–¹æ³•", "æ—¶é—´è§„åˆ’"],
                "input_hint": "è¯·è¾“å…¥ç ”ç©¶é—®é¢˜ï¼Œä¾‹å¦‚ï¼šå¦‚ä½•æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡ï¼Ÿ"
            },
            {
                "id": "story",
                "name": "æ•…äº‹åˆ›ä½œ",
                "description": "åˆ›æ„å†™ä½œå·¥ä½œæµï¼Œç”Ÿæˆå®Œæ•´æ•…äº‹",
                "steps": ["æ„æ€æƒ…èŠ‚", "è§’è‰²å¡‘é€ ", "æ’°å†™åˆç¨¿", "æ¶¦è‰²å®Œå–„"],
                "input_hint": "è¯·è¾“å…¥æ•…äº‹ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼šæ—¶é—´æ—…è¡Œè€…çš„å›°å¢ƒ"
            },
            {
                "id": "product",
                "name": "äº§å“åˆ†æ",
                "description": "ç³»ç»ŸåŒ–çš„äº§å“éœ€æ±‚åˆ†æå’Œè§„åˆ’",
                "steps": ["éœ€æ±‚ç†è§£", "åŠŸèƒ½è®¾è®¡", "æŠ€æœ¯æ–¹æ¡ˆ", "å®æ–½è®¡åˆ’"],
                "input_hint": "è¯·æè¿°äº§å“éœ€æ±‚ï¼Œä¾‹å¦‚ï¼šä¸€ä¸ªå¸®åŠ©å¼€å‘è€…å¿«é€Ÿæ­å»ºAPIçš„å·¥å…·"
            }
        ]
    }


# ========== Routing Agent ç›¸å…³æ¥å£ ==========

@app.post("/api/routing/route")
async def route_request(request: RoutingRequest):
    """æ‰§è¡Œè·¯ç”±å†³ç­–å’Œå¤„ç†"""
    try:
        agent = get_routing_agent(request.scenario, request.strategy)
        result = agent.route(request.input_text)
        
        if not result.success:
            raise HTTPException(
                status_code=500,
                detail=f"è·¯ç”±å¤±è´¥: {result.error_message}"
            )
        
        return {
            "success": True,
            "route_name": result.route_name,
            "route_description": result.route_description,
            "output": result.handler_output,
            "confidence": result.confidence,
            "routing_reason": result.routing_reason,
            "execution_time": result.execution_time
        }
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"è·¯ç”±æ‰§è¡Œå¤±è´¥: {str(e)}")


@app.get("/api/routing/routes")
async def get_routes(scenario: str = "smart_assistant"):
    """è·å–æŒ‡å®šåœºæ™¯çš„æ‰€æœ‰è·¯ç”±ä¿¡æ¯"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ agent æ¥è·å–è·¯ç”±ä¿¡æ¯
        llm_client = GiteeAIClient()
        agent = RoutingAgent(llm_client=llm_client, strategy="hybrid", verbose=False)
        
        # æ³¨å†Œè·¯ç”±
        if scenario == "smart_assistant":
            routes = SmartAssistantRoutes.get_routes(llm_client)
        elif scenario == "developer_assistant":
            routes = DeveloperAssistantRoutes.get_routes(llm_client)
        else:
            raise HTTPException(status_code=400, detail=f"æœªçŸ¥åœºæ™¯: {scenario}")
        
        agent.register_routes(routes)
        
        # è·å–è·¯ç”±ä¿¡æ¯
        routes_info = agent.get_routes_info()
        
        return {
            "scenario": scenario,
            "routes": routes_info,
            "total_count": len(routes_info)
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è·¯ç”±ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.get("/api/routing/scenarios")
async def get_scenarios():
    """è·å–æ‰€æœ‰å¯ç”¨çš„è·¯ç”±åœºæ™¯"""
    return {
        "scenarios": [
            {
                "id": "smart_assistant",
                "name": "æ™ºèƒ½åŠ©æ‰‹",
                "description": "é€šç”¨æ™ºèƒ½åŠ©æ‰‹ï¼Œæ”¯æŒä»£ç ç”Ÿæˆã€å†™ä½œã€åˆ†æã€ç¿»è¯‘ç­‰ä»»åŠ¡",
                "routes": [
                    "ä»£ç ç”Ÿæˆ",
                    "å†…å®¹åˆ›ä½œ",
                    "æ•°æ®åˆ†æ",
                    "ç¿»è¯‘",
                    "é—®ç­”",
                    "æ‘˜è¦æ€»ç»“"
                ]
            },
            {
                "id": "developer_assistant",
                "name": "å¼€å‘è€…åŠ©æ‰‹",
                "description": "ä¸“ä¸ºå¼€å‘è€…è®¾è®¡ï¼Œæ”¯æŒä»£ç å®¡æŸ¥ã€è°ƒè¯•ã€ä¼˜åŒ–ã€æ¶æ„è®¾è®¡",
                "routes": [
                    "ä»£ç å®¡æŸ¥",
                    "è°ƒè¯•",
                    "æ€§èƒ½ä¼˜åŒ–",
                    "æ¶æ„è®¾è®¡"
                ]
            }
        ],
        "strategies": [
            {
                "id": "rule_based",
                "name": "è§„åˆ™è·¯ç”±",
                "description": "åŸºäºæ­£åˆ™è¡¨è¾¾å¼çš„ç²¾ç¡®åŒ¹é…"
            },
            {
                "id": "keyword",
                "name": "å…³é”®è¯è·¯ç”±",
                "description": "åŸºäºå…³é”®è¯çš„å¿«é€ŸåŒ¹é…"
            },
            {
                "id": "llm_based",
                "name": "LLMè·¯ç”±",
                "description": "ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½è·¯ç”±å†³ç­–"
            },
            {
                "id": "hybrid",
                "name": "æ··åˆè·¯ç”±ï¼ˆæ¨èï¼‰",
                "description": "ç»“åˆè§„åˆ™ã€å…³é”®è¯å’ŒLLMçš„ä¼˜åŠ¿"
            }
        ]
    }


# ========== Parallelization Agent ç›¸å…³æ¥å£ ==========

@app.post("/api/parallelization/execute")
async def execute_parallelization(request: ParallelizationRequest):
    """æ‰§è¡Œå¹¶è¡ŒåŒ–ä»»åŠ¡"""
    try:
        agent = get_parallelization_agent(request.max_workers)
        
        # æ ¹æ®åœºæ™¯åˆ›å»ºä»»åŠ¡
        tasks = []
        
        if request.scenario == "multi_perspective":
            tasks = MultiPerspectiveAnalysis.create_tasks(
                request.input_text,
                perspectives=request.perspectives
            )
        
        elif request.scenario == "translation":
            tasks = ParallelTranslation.create_tasks(
                request.input_text,
                target_languages=request.languages
            )
        
        elif request.scenario == "content_gen":
            tasks = ParallelContentGeneration.create_tasks(
                request.input_text,
                sections=request.sections
            )
        
        elif request.scenario == "code_review":
            tasks = ParallelCodeReview.create_tasks(request.input_text)
        
        elif request.scenario == "research":
            tasks = ParallelResearch.create_tasks(
                request.input_text,
                aspects=request.aspects
            )
        
        elif request.scenario == "consensus":
            tasks = ConsensusGenerator.create_tasks(
                request.input_text,
                num_generations=request.num_generations or 5
            )
        
        else:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„åœºæ™¯ç±»å‹: {request.scenario}"
            )
        
        # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡
        result = agent.execute_parallel(
            tasks,
            strategy=ParallelStrategy(request.strategy),
            aggregation=AggregationMethod(request.aggregation),
            batch_size=request.batch_size
        )
        
        return {
            "success": result.success_count > 0,
            "aggregated_result": result.aggregated_result,
            "total_time": result.total_time,
            "parallel_time": result.parallel_time,
            "success_count": result.success_count,
            "failed_count": result.failed_count,
            "strategy": result.strategy,
            "aggregation_method": result.aggregation_method,
            "task_results": [
                {
                    "task_name": r.task_name,
                    "output": r.output,
                    "success": r.success,
                    "execution_time": r.execution_time,
                    "error_message": r.error_message
                }
                for r in result.task_results
            ]
        }
    
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¹¶è¡Œä»»åŠ¡å¤±è´¥: {str(e)}")


@app.post("/api/parallelization/execute/stream")
async def execute_parallelization_stream(request: ParallelizationRequest):
    """æ‰§è¡Œå¹¶è¡ŒåŒ–ä»»åŠ¡ï¼ˆæµå¼ï¼Œå®æ—¶è¿”å›è¿›åº¦ï¼‰"""
    
    async def generate():
        try:
            agent = get_parallelization_agent(request.max_workers)
            
            # æ ¹æ®åœºæ™¯åˆ›å»ºä»»åŠ¡
            tasks = []
            
            if request.scenario == "multi_perspective":
                tasks = MultiPerspectiveAnalysis.create_tasks(
                    request.input_text,
                    perspectives=request.perspectives
                )
            elif request.scenario == "translation":
                tasks = ParallelTranslation.create_tasks(
                    request.input_text,
                    target_languages=request.languages
                )
            elif request.scenario == "content_gen":
                tasks = ParallelContentGeneration.create_tasks(
                    request.input_text,
                    sections=request.sections
                )
            elif request.scenario == "code_review":
                tasks = ParallelCodeReview.create_tasks(request.input_text)
            elif request.scenario == "research":
                tasks = ParallelResearch.create_tasks(
                    request.input_text,
                    aspects=request.aspects
                )
            elif request.scenario == "consensus":
                tasks = ConsensusGenerator.create_tasks(
                    request.input_text,
                    num_generations=request.num_generations or 5
                )
            else:
                yield f"data: {json.dumps({'error': f'ä¸æ”¯æŒçš„åœºæ™¯ç±»å‹: {request.scenario}', 'done': True}, ensure_ascii=False)}\n\n"
                return
            
            # å‘é€ä»»åŠ¡ä¿¡æ¯
            yield f"data: {json.dumps({'type': 'info', 'total_tasks': len(tasks), 'scenario': request.scenario}, ensure_ascii=False)}\n\n"
            
            # æ‰§è¡Œå¹¶è¡Œä»»åŠ¡ï¼ˆè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„åŒ…è£…æ¥å‘é€è¿›åº¦ï¼‰
            import time
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            def execute_task_with_progress(task):
                start_time = time.time()
                try:
                    output = task.handler(task.input_data, agent.llm_client)
                    execution_time = time.time() - start_time
                    return {
                        "task_name": task.name,
                        "output": output,
                        "success": True,
                        "execution_time": execution_time,
                        "error_message": ""
                    }
                except Exception as e:
                    execution_time = time.time() - start_time
                    return {
                        "task_name": task.name,
                        "output": None,
                        "success": False,
                        "execution_time": execution_time,
                        "error_message": str(e)
                    }
            
            task_results = []
            parallel_start = time.time()
            
            with ThreadPoolExecutor(max_workers=request.max_workers) as executor:
                future_to_task = {
                    executor.submit(execute_task_with_progress, task): task
                    for task in tasks
                }
                
                for future in as_completed(future_to_task):
                    result = future.result()
                    task_results.append(result)
                    
                    # å‘é€ä»»åŠ¡å®Œæˆäº‹ä»¶
                    yield f"data: {json.dumps({'type': 'task_complete', 'task_name': result['task_name'], 'success': result['success'], 'completed': len(task_results), 'total': len(tasks)}, ensure_ascii=False)}\n\n"
            
            parallel_time = time.time() - parallel_start
            
            # èšåˆç»“æœ
            from src.shuyixiao_agent.agents.parallelization_agent import TaskResult
            
            task_result_objects = [
                TaskResult(
                    task_name=r["task_name"],
                    output=r["output"],
                    success=r["success"],
                    execution_time=r["execution_time"],
                    error_message=r["error_message"]
                )
                for r in task_results
            ]
            
            aggregated = agent._aggregate_results(
                task_result_objects,
                AggregationMethod(request.aggregation)
            )
            
            total_time = time.time() - parallel_start
            success_count = sum(1 for r in task_results if r["success"])
            
            # å‘é€æœ€ç»ˆç»“æœ
            yield f"data: {json.dumps({'type': 'done', 'aggregated_result': aggregated, 'total_time': total_time, 'parallel_time': parallel_time, 'success_count': success_count, 'task_results': task_results}, ensure_ascii=False)}\n\n"
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            error_msg = f"æ‰§è¡Œå¹¶è¡Œä»»åŠ¡å¤±è´¥: {str(e)}"
            yield f"data: {json.dumps({'error': error_msg, 'done': True}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.get("/api/parallelization/scenarios")
async def get_parallelization_scenarios():
    """è·å–æ‰€æœ‰å¯ç”¨çš„å¹¶è¡ŒåŒ–åœºæ™¯"""
    return {
        "scenarios": [
            {
                "id": "multi_perspective",
                "name": "å¤šè§’åº¦åˆ†æ",
                "description": "ä»å¤šä¸ªè§’åº¦åŒæ—¶åˆ†æåŒä¸€é—®é¢˜",
                "default_perspectives": [
                    "æŠ€æœ¯è§’åº¦",
                    "å•†ä¸šè§’åº¦",
                    "ç”¨æˆ·ä½“éªŒè§’åº¦",
                    "é£é™©å’ŒæŒ‘æˆ˜è§’åº¦",
                    "åˆ›æ–°å’Œæœºä¼šè§’åº¦"
                ],
                "input_hint": "è¯·è¾“å…¥è¦åˆ†æçš„ä¸»é¢˜æˆ–é—®é¢˜"
            },
            {
                "id": "translation",
                "name": "å¹¶è¡Œç¿»è¯‘",
                "description": "åŒæ—¶å°†æ–‡æœ¬ç¿»è¯‘æˆå¤šç§è¯­è¨€",
                "default_languages": ["è‹±è¯­", "æ—¥è¯­", "æ³•è¯­", "å¾·è¯­", "è¥¿ç­ç‰™è¯­"],
                "input_hint": "è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬"
            },
            {
                "id": "content_gen",
                "name": "å¹¶è¡Œå†…å®¹ç”Ÿæˆ",
                "description": "åŒæ—¶ç”Ÿæˆæ–‡æ¡£çš„ä¸åŒç« èŠ‚",
                "default_sections": [
                    "ç®€ä»‹å’ŒèƒŒæ™¯",
                    "æ ¸å¿ƒæ¦‚å¿µ",
                    "å®è·µç¤ºä¾‹",
                    "æœ€ä½³å®è·µ",
                    "å¸¸è§é—®é¢˜"
                ],
                "input_hint": "è¯·è¾“å…¥æ–‡æ¡£ä¸»é¢˜"
            },
            {
                "id": "code_review",
                "name": "å¹¶è¡Œä»£ç å®¡æŸ¥",
                "description": "ä»å¤šä¸ªç»´åº¦åŒæ—¶å®¡æŸ¥ä»£ç ",
                "aspects": [
                    "ä»£ç è´¨é‡",
                    "æ€§èƒ½åˆ†æ",
                    "å®‰å…¨æ£€æŸ¥",
                    "æœ€ä½³å®è·µ",
                    "æµ‹è¯•å»ºè®®"
                ],
                "input_hint": "è¯·ç²˜è´´è¦å®¡æŸ¥çš„ä»£ç "
            },
            {
                "id": "research",
                "name": "å¹¶è¡Œç ”ç©¶",
                "description": "åŒæ—¶ç ”ç©¶é—®é¢˜çš„ä¸åŒæ–¹é¢",
                "default_aspects": [
                    "å†å²èƒŒæ™¯å’Œå‘å±•",
                    "å½“å‰çŠ¶æ€å’Œè¶‹åŠ¿",
                    "ä¸»è¦æ–¹æ³•å’ŒæŠ€æœ¯",
                    "å®é™…åº”ç”¨æ¡ˆä¾‹",
                    "æœªæ¥å±•æœ›å’ŒæŒ‘æˆ˜"
                ],
                "input_hint": "è¯·è¾“å…¥ç ”ç©¶é—®é¢˜"
            },
            {
                "id": "consensus",
                "name": "å…±è¯†ç”Ÿæˆ",
                "description": "é€šè¿‡å¤šæ¬¡ç”Ÿæˆå¯»æ‰¾æœ€ä½³ç­”æ¡ˆ",
                "num_generations": 5,
                "input_hint": "è¯·è¾“å…¥é—®é¢˜æˆ–æç¤ºè¯"
            }
        ],
        "strategies": [
            {
                "id": "full_parallel",
                "name": "å…¨å¹¶è¡Œï¼ˆæ¨èï¼‰",
                "description": "æ‰€æœ‰ä»»åŠ¡åŒæ—¶æ‰§è¡Œï¼Œæœ€å¤§åŒ–å¹¶è¡Œæ•ˆç‡"
            },
            {
                "id": "batch_parallel",
                "name": "æ‰¹é‡å¹¶è¡Œ",
                "description": "å°†ä»»åŠ¡åˆ†æ‰¹æ‰§è¡Œï¼Œæ§åˆ¶èµ„æºä½¿ç”¨"
            },
            {
                "id": "pipeline",
                "name": "æµæ°´çº¿",
                "description": "è€ƒè™‘ä»»åŠ¡ä¾èµ–å…³ç³»ï¼Œåˆ†é˜¶æ®µå¹¶è¡Œ"
            },
            {
                "id": "vote",
                "name": "æŠ•ç¥¨",
                "description": "å¤šä¸ªç›¸åŒä»»åŠ¡å¹¶è¡Œï¼Œç»“æœæŠ•ç¥¨å†³å®š"
            },
            {
                "id": "ensemble",
                "name": "é›†æˆ",
                "description": "å¤šä¸ªä¸åŒæ–¹æ³•å¹¶è¡Œï¼Œç»“æœèåˆ"
            }
        ],
        "aggregation_methods": [
            {
                "id": "merge",
                "name": "åˆå¹¶",
                "description": "å°†æ‰€æœ‰ç»“æœåˆå¹¶åˆ°å­—å…¸"
            },
            {
                "id": "concat",
                "name": "è¿æ¥",
                "description": "å°†æ‰€æœ‰ç»“æœè¿æ¥æˆæ–‡æœ¬"
            },
            {
                "id": "first",
                "name": "ç¬¬ä¸€ä¸ª",
                "description": "ä½¿ç”¨ç¬¬ä¸€ä¸ªå®Œæˆçš„ç»“æœ"
            },
            {
                "id": "best",
                "name": "æœ€ä½³",
                "description": "é€‰æ‹©è´¨é‡æœ€é«˜çš„ç»“æœ"
            },
            {
                "id": "summarize",
                "name": "æ€»ç»“ï¼ˆæ¨èï¼‰",
                "description": "ä½¿ç”¨LLMæ€»ç»“æ‰€æœ‰ç»“æœ"
            },
            {
                "id": "vote",
                "name": "æŠ•ç¥¨",
                "description": "é€‰æ‹©æœ€å¸¸è§çš„ç»“æœ"
            },
            {
                "id": "consensus",
                "name": "å…±è¯†",
                "description": "ä½¿ç”¨LLMå¯»æ‰¾å…±è¯†"
            }
        ]
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "shuyixiao_agent.web_app:app",
        host="0.0.0.0",
        port=8001,
        reload=True
    )

