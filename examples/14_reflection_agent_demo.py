"""
Reflection Agent ç¤ºä¾‹ - æ¼”ç¤ºåæ€ä»£ç†çš„å„ç§åŠŸèƒ½

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Reflection Agent é€šè¿‡è‡ªæˆ‘æ‰¹åˆ¤å’Œè¿­ä»£æ”¹è¿›æ¥æå‡è¾“å‡ºè´¨é‡ã€‚
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.shuyixiao_agent.gitee_ai_client import GiteeAIClient
from src.shuyixiao_agent.agents.reflection_agent import (
    ReflectionAgent,
    ReflectionStrategy,
    ContentReflection,
    CodeReflection,
    AnalysisReflection,
    TranslationReflection
)


def print_separator(title=""):
    """æ‰“å°åˆ†éš”çº¿"""
    print("\n" + "=" * 60)
    if title:
        print(f"  {title}")
        print("=" * 60)
    print()


def demo_simple_reflection():
    """æ¼”ç¤ºç®€å•åæ€"""
    print_separator("ç¤ºä¾‹ 1: ç®€å•åæ€ - æ”¹è¿›ä¸€ç¯‡çŸ­æ–‡")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=3,
        score_threshold=0.85,
        verbose=True
    )
    
    task = """å†™ä¸€ç¯‡å…³äº"AIä¸äººç±»åä½œ"çš„çŸ­æ–‡ï¼Œ200å­—å·¦å³ã€‚"""
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=ReflectionStrategy.SIMPLE
    )
    
    if result.success:
        print("\nâœ¨ æœ€ç»ˆä¼˜åŒ–åçš„å†…å®¹ï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  - æ€»è¿­ä»£æ¬¡æ•°: {result.total_iterations}")
        print(f"  - æœ€ç»ˆè¯„åˆ†: {result.final_score:.2f}")
        print(f"  - æ€»è€—æ—¶: {result.total_time:.2f}ç§’")
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def demo_multi_aspect_reflection():
    """æ¼”ç¤ºå¤šç»´åº¦åæ€"""
    print_separator("ç¤ºä¾‹ 2: å¤šç»´åº¦åæ€ - ä¼˜åŒ–ä»£ç ")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=3,
        score_threshold=0.9,  # æ›´é«˜çš„è´¨é‡è¦æ±‚
        verbose=True
    )
    
    # æä¾›åˆå§‹ä»£ç 
    initial_code = """
def find_max(numbers):
    max_num = numbers[0]
    for num in numbers:
        if num > max_num:
            max_num = num
    return max_num

result = find_max([3, 1, 4, 1, 5, 9, 2, 6])
print(result)
"""
    
    result = agent.reflect_and_improve(
        task="ä¼˜åŒ–è¿™ä¸ªæŸ¥æ‰¾æœ€å¤§å€¼çš„Pythonå‡½æ•°",
        initial_content=initial_code,
        strategy=ReflectionStrategy.MULTI_ASPECT,
        criteria=CodeReflection.get_criteria()
    )
    
    if result.success:
        print("\nâœ¨ ä¼˜åŒ–åçš„ä»£ç ï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
        print(f"\nğŸ’¡ æ”¹è¿›æ€»ç»“ï¼š")
        print(result.improvement_summary)
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def demo_debate_reflection():
    """æ¼”ç¤ºè¾©è®ºå¼åæ€"""
    print_separator("ç¤ºä¾‹ 3: è¾©è®ºå¼åæ€ - åˆ†ææŠ€æœ¯æ–¹æ¡ˆ")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=2,
        score_threshold=0.8,
        verbose=True
    )
    
    task = """åˆ†æå¾®æœåŠ¡æ¶æ„ç›¸æ¯”å•ä½“æ¶æ„çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ç»™å‡ºé€‰æ‹©å»ºè®®ã€‚"""
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=ReflectionStrategy.DEBATE,  # ä½¿ç”¨è¾©è®ºå¼ç­–ç•¥
        criteria=AnalysisReflection.get_criteria()
    )
    
    if result.success:
        print("\nâœ¨ æœ€ç»ˆåˆ†æç»“æœï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
        
        print("\nğŸ“œ åæ€å†å²ï¼š")
        for i, reflection in enumerate(result.reflection_history, 1):
            print(f"\nç¬¬ {i} è½®åæ€:")
            print(f"  è¯„åˆ†: {reflection.score:.2f}")
            print(f"  æ‰¹è¯„: {reflection.critique[:100]}...")
            print(f"  æ”¹è¿›å»ºè®®æ•°: {len(reflection.improvements)}")
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def demo_expert_reflection():
    """æ¼”ç¤ºä¸“å®¶åæ€"""
    print_separator("ç¤ºä¾‹ 4: ä¸“å®¶åæ€ - ä¸“ä¸šé¢†åŸŸè¯„ä¼°")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=3,
        score_threshold=0.85,
        verbose=True
    )
    
    task = """è®¾è®¡ä¸€ä¸ªé«˜å¹¶å‘çš„åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿæ¶æ„æ–¹æ¡ˆã€‚"""
    
    context = {
        'expert_role': 'èµ„æ·±ç³»ç»Ÿæ¶æ„å¸ˆ',
        'expert_expertise': '15å¹´å¤§è§„æ¨¡åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡ç»éªŒï¼Œæ“…é•¿é«˜å¹¶å‘æ¶æ„'
    }
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=ReflectionStrategy.EXPERT,
        context=context
    )
    
    if result.success:
        print("\nâœ¨ ä¸“å®¶ä¼˜åŒ–åçš„æ–¹æ¡ˆï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
        print(f"\nè´¨é‡æå‡: {result.final_score - result.reflection_history[0].score:+.2f}")
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def demo_translation_reflection():
    """æ¼”ç¤ºç¿»è¯‘åæ€"""
    print_separator("ç¤ºä¾‹ 5: ç¿»è¯‘ä¼˜åŒ– - æ”¹è¿›ç¿»è¯‘è´¨é‡")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=3,
        score_threshold=0.9,
        verbose=True
    )
    
    # ä¸€æ®µéœ€è¦ç¿»è¯‘çš„è‹±æ–‡
    task = """å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š
    
"Artificial Intelligence is not just about automation, it's about augmenting human capabilities 
and enabling us to solve problems that were previously intractable. The future lies in the 
seamless collaboration between humans and AI systems."
"""
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=ReflectionStrategy.MULTI_ASPECT,
        criteria=TranslationReflection.get_criteria()
    )
    
    if result.success:
        print("\nâœ¨ ä¼˜åŒ–åçš„è¯‘æ–‡ï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def demo_iterative_improvement():
    """æ¼”ç¤ºè¿­ä»£æ”¹è¿›è¿‡ç¨‹"""
    print_separator("ç¤ºä¾‹ 6: è¿­ä»£æ”¹è¿› - è§‚å¯Ÿè´¨é‡æå‡è¿‡ç¨‹")
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=5,  # æ›´å¤šè¿­ä»£æ¬¡æ•°
        score_threshold=0.95,  # å¾ˆé«˜çš„è´¨é‡è¦æ±‚
        verbose=False  # å…³é—­è¯¦ç»†è¾“å‡ºï¼Œæˆ‘ä»¬è‡ªå·±å¤„ç†
    )
    
    task = """å†™ä¸€ç¯‡å…³äº"é‡å­è®¡ç®—çš„æœªæ¥"çš„ç§‘æ™®æ–‡ç« ï¼Œ300å­—å·¦å³ã€‚"""
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=ReflectionStrategy.MULTI_ASPECT,
        criteria=ContentReflection.get_criteria()
    )
    
    if result.success:
        print("ğŸ“ˆ è´¨é‡æ”¹è¿›è½¨è¿¹ï¼š")
        print()
        for reflection in result.reflection_history:
            bar_length = int(reflection.score * 50)
            bar = "â–ˆ" * bar_length + "â–‘" * (50 - bar_length)
            print(f"ç¬¬{reflection.iteration}è½®: [{bar}] {reflection.score:.2f}")
        
        print(f"\næ€»æå‡: {result.final_score - result.reflection_history[0].score:+.3f}")
        print(f"è¾¾åˆ°é˜ˆå€¼: {'æ˜¯' if result.final_score >= 0.95 else 'å¦'}")
        
        print("\nâœ¨ æœ€ç»ˆæ–‡ç« ï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print_separator("äº¤äº’å¼ Reflection Agent æ¼”ç¤º")
    
    print("æ¬¢è¿ä½¿ç”¨ Reflection Agentï¼")
    print("\nè¯·é€‰æ‹©ä¸€ä¸ªåœºæ™¯ï¼š")
    print("1. å†…å®¹åˆ›ä½œä¼˜åŒ–")
    print("2. ä»£ç è´¨é‡æå‡")
    print("3. åˆ†ææŠ¥å‘Šæ”¹è¿›")
    print("4. ç¿»è¯‘è´¨é‡ä¼˜åŒ–")
    print("5. è‡ªå®šä¹‰ä»»åŠ¡")
    print("0. é€€å‡º")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (0-5): ").strip()
    
    if choice == "0":
        print("\nå†è§ï¼")
        return
    
    llm_client = GiteeAIClient()
    agent = ReflectionAgent(
        llm_client=llm_client,
        max_iterations=3,
        score_threshold=0.85,
        verbose=True
    )
    
    criteria = None
    strategy = ReflectionStrategy.MULTI_ASPECT
    
    if choice == "1":
        criteria = ContentReflection.get_criteria()
        task = input("\nè¯·è¾“å…¥å†…å®¹åˆ›ä½œä»»åŠ¡: ").strip()
    elif choice == "2":
        criteria = CodeReflection.get_criteria()
        task = input("\nè¯·è¾“å…¥ä»£ç æˆ–ä»£ç ä»»åŠ¡: ").strip()
    elif choice == "3":
        criteria = AnalysisReflection.get_criteria()
        task = input("\nè¯·è¾“å…¥åˆ†æä»»åŠ¡: ").strip()
    elif choice == "4":
        criteria = TranslationReflection.get_criteria()
        task = input("\nè¯·è¾“å…¥ç¿»è¯‘ä»»åŠ¡: ").strip()
    elif choice == "5":
        task = input("\nè¯·è¾“å…¥ä»»åŠ¡æè¿°: ").strip()
        print("\né€‰æ‹©åæ€ç­–ç•¥ï¼š")
        print("1. ç®€å•åæ€")
        print("2. å¤šç»´åº¦åæ€ï¼ˆæ¨èï¼‰")
        print("3. è¾©è®ºå¼åæ€")
        print("4. ä¸“å®¶åæ€")
        strategy_choice = input("è¯·é€‰æ‹© (1-4): ").strip()
        
        strategy_map = {
            "1": ReflectionStrategy.SIMPLE,
            "2": ReflectionStrategy.MULTI_ASPECT,
            "3": ReflectionStrategy.DEBATE,
            "4": ReflectionStrategy.EXPERT
        }
        strategy = strategy_map.get(strategy_choice, ReflectionStrategy.MULTI_ASPECT)
        
        if strategy == ReflectionStrategy.EXPERT:
            expert_role = input("è¯·è¾“å…¥ä¸“å®¶è§’è‰² (ä¾‹å¦‚: èµ„æ·±æ¶æ„å¸ˆ): ").strip()
            expert_expertise = input("è¯·è¾“å…¥ä¸“ä¸šé¢†åŸŸ (ä¾‹å¦‚: 10å¹´åˆ†å¸ƒå¼ç³»ç»Ÿç»éªŒ): ").strip()
            context = {
                'expert_role': expert_role or 'é¢†åŸŸä¸“å®¶',
                'expert_expertise': expert_expertise or 'ç›¸å…³é¢†åŸŸä¸“ä¸šçŸ¥è¯†'
            }
        else:
            context = {}
    else:
        print("æ— æ•ˆçš„é€‰é¡¹ï¼")
        return
    
    if not task:
        print("ä»»åŠ¡ä¸èƒ½ä¸ºç©ºï¼")
        return
    
    print("\nå¼€å§‹åæ€å’Œæ”¹è¿›...")
    
    result = agent.reflect_and_improve(
        task=task,
        strategy=strategy,
        criteria=criteria,
        context=context if choice == "5" and strategy == ReflectionStrategy.EXPERT else {}
    )
    
    if result.success:
        print("\n" + "=" * 60)
        print("âœ¨ åæ€å®Œæˆï¼")
        print("=" * 60)
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  - è¿­ä»£æ¬¡æ•°: {result.total_iterations}")
        print(f"  - æœ€ç»ˆè¯„åˆ†: {result.final_score:.2f}")
        print(f"  - è´¨é‡æå‡: {result.final_score - result.reflection_history[0].score:+.2f}")
        print(f"  - æ€»è€—æ—¶: {result.total_time:.2f}ç§’")
        
        print(f"\nâœ¨ æœ€ç»ˆç»“æœï¼š")
        print("-" * 60)
        print(result.final_content)
        print("-" * 60)
        
        print(f"\nğŸ’¡ æ”¹è¿›æ€»ç»“ï¼š")
        print(result.improvement_summary)
    else:
        print(f"\nâŒ åæ€å¤±è´¥: {result.error_message}")


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Reflection Agent æ¼”ç¤ºç¨‹åº                          â•‘
â•‘                                                               â•‘
â•‘  é€šè¿‡è‡ªæˆ‘æ‰¹åˆ¤å’Œè¿­ä»£æ”¹è¿›æå‡è¾“å‡ºè´¨é‡                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nè¯·é€‰æ‹©æ¼”ç¤ºæ¨¡å¼ï¼š")
    print("1. è¿è¡Œæ‰€æœ‰é¢„å®šä¹‰ç¤ºä¾‹")
    print("2. ç®€å•åæ€ç¤ºä¾‹")
    print("3. å¤šç»´åº¦åæ€ç¤ºä¾‹")
    print("4. è¾©è®ºå¼åæ€ç¤ºä¾‹")
    print("5. ä¸“å®¶åæ€ç¤ºä¾‹")
    print("6. ç¿»è¯‘ä¼˜åŒ–ç¤ºä¾‹")
    print("7. è¿­ä»£æ”¹è¿›è¿‡ç¨‹ç¤ºä¾‹")
    print("8. äº¤äº’å¼æ¼”ç¤º")
    print("0. é€€å‡º")
    
    choice = input("\nè¯·è¾“å…¥é€‰é¡¹ (0-8): ").strip()
    
    if choice == "0":
        print("\nå†è§ï¼")
        return
    elif choice == "1":
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        demo_simple_reflection()
        demo_multi_aspect_reflection()
        demo_debate_reflection()
        demo_expert_reflection()
        demo_translation_reflection()
        demo_iterative_improvement()
    elif choice == "2":
        demo_simple_reflection()
    elif choice == "3":
        demo_multi_aspect_reflection()
    elif choice == "4":
        demo_debate_reflection()
    elif choice == "5":
        demo_expert_reflection()
    elif choice == "6":
        demo_translation_reflection()
    elif choice == "7":
        demo_iterative_improvement()
    elif choice == "8":
        interactive_demo()
    else:
        print("æ— æ•ˆçš„é€‰é¡¹ï¼")
        return
    
    print("\n" + "=" * 60)
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - Reflection é€šè¿‡å¤šè½®åæ€å’Œæ”¹è¿›æ˜¾è‘—æå‡è¾“å‡ºè´¨é‡")
    print("  - ä¸åŒç­–ç•¥é€‚ç”¨äºä¸åŒåœºæ™¯")
    print("  - å¯ä»¥é€šè¿‡è°ƒæ•´è¿­ä»£æ¬¡æ•°å’Œè´¨é‡é˜ˆå€¼æ§åˆ¶ä¼˜åŒ–ç¨‹åº¦")
    print("  - æŸ¥çœ‹ ğŸ¯ Reflection Agent åŠŸèƒ½å®Œæˆï¼.md äº†è§£æ›´å¤šä¿¡æ¯")


if __name__ == "__main__":
    main()

