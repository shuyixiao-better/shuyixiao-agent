# ============================================
# Gitee AI API 配置示例
# ============================================
# 
# 使用方法：
# 1. 复制此文件为 .env
# 2. 填入你的实际配置值
# 3. 或者在 PyCharm 中直接配置环境变量
#
# PyCharm 配置方法：
# 1. 打开 Run -> Edit Configurations
# 2. 选择你的运行配置（或创建新配置）
# 3. 找到 Environment variables 选项
# 4. 点击右侧的文件夹图标
# 5. 添加下面的环境变量（去掉注释符号#）
# 6. 点击 OK 保存
#
# ============================================

# Gitee AI API 密钥（必填）
# 访问地址获取： https://ai.gitee.com/
GITEE_AI_API_KEY=your_api_key_here

# Gitee AI API 基础 URL（可选，默认值如下）
# 官方 API 地址
GITEE_AI_BASE_URL=https://ai.gitee.com/v1

# 默认模型名称（可选）
# 可选模型列表： https://ai.gitee.com/serverless
# 常用模型：DeepSeek-V3, Qwen, GLM-4 等
GITEE_AI_MODEL=DeepSeek-V3

# ============================================
# Agent 配置
# ============================================

# Agent 最大迭代次数
AGENT_MAX_ITERATIONS=10

# 是否输出详细日志（true/false）
AGENT_VERBOSE=true

# ============================================
# 请求配置
# ============================================

# 请求超时时间（秒）
REQUEST_TIMEOUT=60

# 最大重试次数
MAX_RETRIES=3

# ============================================
# 故障转移配置
# ============================================

# 是否启用故障转移（true/false）
ENABLE_FAILOVER=true

# ============================================
# SSL/网络配置
# ============================================

# 是否验证 SSL 证书（true/false）
# 如果遇到 SSL 连接错误，可以设置为 false
# 注意：生产环境建议保持为 true 以确保安全性
# Windows 系统常见 SSL 错误可通过设置为 false 解决
SSL_VERIFY=false

# ============================================
# RAG（检索增强生成）配置
# ============================================

# 向量数据库存储路径（可选，默认：./data/chroma）
# CHROMA_PERSIST_DIRECTORY=./data/chroma

# 是否使用云端嵌入服务（推荐：true，启动更快）
USE_CLOUD_EMBEDDING=true

# 云端嵌入模型（当 USE_CLOUD_EMBEDDING=true 时使用）
CLOUD_EMBEDDING_MODEL=bge-large-zh-v1.5

# 是否使用云端重排序服务（推荐：true）
USE_CLOUD_RERANKER=true

# 云端重排序模型（当 USE_CLOUD_RERANKER=true 时使用）
CLOUD_RERANKER_MODEL=bge-reranker-base

# ============================================
# 模型分配配置（高级）
# ============================================

# Agent 专用模型（留空则使用主对话模型）
# AGENT_MODEL=GLM-4-Flash

# 查询优化模型（留空则使用主对话模型）
# QUERY_OPTIMIZER_MODEL=Qwen2.5-14B-Instruct